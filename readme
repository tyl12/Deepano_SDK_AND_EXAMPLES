请仔细阅读本文本的内容:谢谢！
[1]本套模组（ma2450）集有摄像头ov5658,可用于解析caffemodel的大部分算法模型，使用之前，需要使用ncsdk的转换工具mvNCCompiler，将caffemodel转化为mv模组可用的blob格式数据.
[2]测试model：链接: https://pan.baidu.com/s/1xf7sqFbwDdqisszKilpb0w 密码: 8ajp
[3]linux下SDK中test.cpp下的编译步骤：
   sh ./install.sh
执行：需要将ld_api.so加入到动态库当中，编译和执行是两种不同的
调用方法：sudo ./dp_test [commond][options]  在主函数中有相关命令：例如打开摄像头：sudo  ./dp_test start_video或者测试tiny-yolo-v2模型，可按如下操作：sudo ./dp_test test_whole_model_1_video_tiny_yolo_v2
或者其他模型，可参照test.cpp中的2343-2361中提供的接口，具体使用方法如，测试googleNet模型，则sudo ./dp_test test_whole_model_1_video_googleNet
[4]windows：可在vs2013,2015下编译，安装usb驱动的方法：访问http://zadig.akeo.ie，根据上面提示下载工具并安装驱动
   本套sdk附带的demo_model,目前只能在ubuntu16.04下使用，windows下没有集成开发，但是本套sdk提供了windows版本的dll和lib，是可以在windows下vs里面使用的.
[5]本SDK相关API简介：
   1、typedef void(*dp_video_frame_cb_t)(dp_img_t *img, void *param);//接收从设备返回的视频流回调接口
   2、typedef void(*dp_first_blob_outresult_back_cb_t)(float * result,void *param);int dp_register_video_frame_cb(dp_video_frame_cb_t cb, void *param);//接收解析第一blob之后的原始结果的回调函数接口
   3、typedef void(*dp_send_to_device_box_cb_t)(dp_image_box_t *box,void *param);//如果解析两个blob，则调用此回调函数，向设备端传输minibox坐标值
   4、typedef void(*dp_second_blob_outresult_back_cb_t)(void * result,void *param)；int dp_register_send_to_box_device_cb(dp_send_to_device_box_cb_t cb, void *param);//接收解析第二blob原始结果的回调函数接口
   5、EXTERN DLL int dp_set_blob_parms(int num_model,dp_blob_parm_t *param);//向设备端发送blob相关参数，注意，num_blob，表示向设备需要传输的个数
   6、EXTERN DLL int dp_update_model(const char* filename);//传输第一个blob
   7、EXTERN DLL int dp_update_model_2(const char* filename);//传输第二个blob
   8、EXTERN DLL int dp_start_camera_video();//打开摄像头获取视频流
   9、EXTERN DLL int dp_start_camera();//打开摄像头

[6]使用测试用例步骤：
   1-- cdk: 解析blob的一般步骤：
   开机（识别usb设备，需登上10s左右）->向设备端传输一个或两个blob的相关初始化参数->传输相应个数的blob->传输blob的mean和std(如果没有，则必须设mean为0,std为1,否则系统报错)->调用dp_start_camera()接口，设备端开始解析图像。
  （1）使用板子只解析一个blob，则可以借鉴test.cpp中的接口中的操作方法。
  （2）使用板子解析两个blob的时候，则可以借鉴test.cpp中的test_whole_model_2_video接口中的操作方法。
  （3）关于系统初始化过程中的一些参数说明：
  （4）dp_blob_parm_t
  {
        int IsTensor_model;  //神经网络是tensor网络框架还是caffe网络框架
	int InputSize_width; //神经网络入口的图片尺寸
	int InputSize_height;//神经网络入口的图片尺寸
	int Output_num;//神经网络解析之后原始的数据长度，等于神经棒上mvnvGetResult()接口获取的原始数据长度; 
  }
 （5）dp_image_box_t{
       int x1;//box宽起始位
       int x2;//box宽终止位
       int y1;//box高起始位
       int y2;//box高终止位
}
 （6）typedef struct _dp_netMean
  {
    float R_mean;//图像前处理，r通道均值
    float G_mean;//图像前处理，g通道均值
    float B_mean;//图像前处理，b通道均值
    float Std;//图像前处理，std标准差
}dp_netMean;如果模型没有对图像进行前处理，则设为（0,0,0,1）
   2--cdk:解析blob之后的原始数据结果为void*数据类型，该数据的后续处理过程，可通过注册回调函数dp_register_box_device_cb(dp_first_blob_outresult_back_cb_t cb, void *param)进行相应处理
   与设备通信的相关命令在dp_type.h文件中
   ps:this version of cdk only run 8 shaves with blob,the other 4 shaves are used to image preprocessing. 
[7]通过模型测试：
   ncappzoo里面大部分模型都可运行，只有inception_v4模型，目前有些问题，注意:
  1）.tinyYolo:解析算法不是太准确,如果你有更好的解析代码，可以联系我：yuqj@deepano.com
  2).inception_v4:现在系统无法运行此模型
  后续我还会在继续研究解析算法，yolo和ssd一旦有更好的解析算法，我会持续更新的
[8]注意：
  1).本测试样例所有模型的解析算法均为本人借鉴ncappzoo里面的解析算法，可能会有些不准确，如果您有非常好的准确的解析算法，请与我联系:yuqj@deepano.com,非常感谢
  2).本套ma2450模组芯片，host端一旦终止，如果想要再次运行host端程序，需要重新插拔usb
  3).本套ma2450模组芯片，host端不可直接这样执行 sudo ./dp_test这样的命令,只能一次运行一个接口，例如：sudo ./dp_test test_whole_model_1_video_TinyYoloNet,这是因为直接运行，包含运行了所有接口，会导致运行更新固件接口，会损坏固件
  4).本套ma2450模组芯片，device端图像前处理方法均为resize->yuv->rgb->fp16->bgr;因此本套所有模型的结果可能不会非常准确，如果客户有不同的图像前处理方式，需要单独定制
  5).本套ma2450模组芯片, Blob_size_1<=150M,Blob_size_2<=85M

